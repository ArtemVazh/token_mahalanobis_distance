{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "def expand_config(dict_config):\n",
    "    keys, values = zip(*dict_config.items())\n",
    "    permutations_dicts = [dict(zip(keys, v)) for v in it.product(*values)]\n",
    "    return permutations_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bash(configs, cuda_devices, tasks, generate_func, filename='', scripts=\"run_polygraph_2.py\"):\n",
    "    full_config = 'cd ../'\n",
    "    j = 0\n",
    "    n_devices = len(cuda_devices)\n",
    "    for i, mc_configs in enumerate(configs):\n",
    "        for conf in expand_config(mc_configs):\n",
    "            for task_name in tasks:\n",
    "                conf[\"task\"] = task_name\n",
    "                if not (\"12b\" in conf[\"model\"]):\n",
    "                    base_arg = f'CUDA_VISIBLE_DEVICES={cuda_devices[j%n_devices]} HYDRA_CONFIG=./configs/polygraph_eval_{task_name}.yaml python {scripts}'\n",
    "                else:\n",
    "                    base_arg = f'CUDA_VISIBLE_DEVICES={cuda_devices[j%n_devices]},{cuda_devices[(j+1)%n_devices]} HYDRA_CONFIG=./configs/polygraph_eval_{task_name}.yaml python {scripts}'\n",
    "                    j+=1\n",
    "                    \n",
    "                new_task = copy.deepcopy(base_arg)\n",
    "                args = ' '.join(generate_func[i](conf))\n",
    "                new_task += f' {args}'\n",
    "                if (j+1)%n_devices!=0: \n",
    "                    new_task += ' &'\n",
    "                else:\n",
    "                    new_task += '\\nwait'\n",
    "                full_config += '\\n' + new_task if len(full_config) else new_task\n",
    "                j+=1\n",
    "                \n",
    "    with open (f'../scripts/{filename}', 'w') as rsh:\n",
    "        rsh.write(full_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate_train_str_config() missing 1 required positional argument: 'task_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m      7\u001b[0m train_configs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample_train_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1000\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples_n\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     19\u001b[0m cuda_devices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m \u001b[43mgenerate_bash\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_configs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda_devices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mgenerate_train_str_config\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun_tmd_exps_p1.sh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m, in \u001b[0;36mgenerate_bash\u001b[0;34m(configs, cuda_devices, tasks, generate_func, filename, scripts)\u001b[0m\n\u001b[1;32m     13\u001b[0m     j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m new_task \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(base_arg)\n\u001b[0;32m---> 16\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mgenerate_func\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     17\u001b[0m new_task \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m%\u001b[39mn_devices\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m: \n",
      "\u001b[0;31mTypeError\u001b[0m: generate_train_str_config() missing 1 required positional argument: 'task_name'"
     ]
    }
   ],
   "source": [
    "tasks = ['coqa', 'sciq', 'triviaqa', 'truthfullqa', 'mmlu']\n",
    "\n",
    "layers = {\"google/gemma-7b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(27)])),\n",
    "          \"meta-llama/Meta-Llama-3-8B\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(31)])),\n",
    "          \"stabilityai/stablelm-2-12b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(39)]))}\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [1000],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['google/gemma-7b', 'meta-llama/Meta-Llama-3-8B'],# 'stabilityai/stablelm-2-12b'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_9'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p1.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'subsample_gsm8k_train_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 17\u001b[0m\n\u001b[1;32m      3\u001b[0m train_configs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample_train_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1000\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples_n\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     15\u001b[0m cuda_devices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m \u001b[43mgenerate_bash\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_configs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda_devices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mgenerate_train_str_config\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun_tmd_exps_p2.sh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m, in \u001b[0;36mgenerate_bash\u001b[0;34m(configs, cuda_devices, tasks, generate_func, filename, scripts)\u001b[0m\n\u001b[1;32m     13\u001b[0m     j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m new_task \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(base_arg)\n\u001b[0;32m---> 16\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mgenerate_func\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     17\u001b[0m new_task \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m%\u001b[39mn_devices\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m: \n",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m, in \u001b[0;36mgenerate_train_str_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      5\u001b[0m config_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgsm8k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedquad\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m----> 8\u001b[0m     config_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample_train_dataset=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubsample_gsm8k_train_dataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     config_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample_train_dataset=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample_train_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'subsample_gsm8k_train_dataset'"
     ]
    }
   ],
   "source": [
    "tasks = ['gsm8k', 'xsum', 'wmt14_deen', 'medquad', 'cnn', 'samsum', 'pubmedqa']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [1000],\n",
    "    'subsample_background_train_dataset': [500],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['google/gemma-7b', 'meta-llama/Meta-Llama-3-8B'],# 'stabilityai/stablelm-2-12b'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_9'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0,1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p2.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['sciq', 'coqa', 'triviaqa', 'truthfullqa', 'mmlu', 'samsum', 'pubmedqa', 'wmt14_deen', 'cnn']\n",
    "\n",
    "layers = {\"google/gemma-7b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(27)])),\n",
    "          \"meta-llama/Meta-Llama-3-8B\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(31)])),\n",
    "          \"stabilityai/stablelm-2-12b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(39)]))}\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['google/gemma-7b', 'meta-llama/Meta-Llama-3-8B'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_3'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p1_1.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['gsm8k', 'xsum', 'medquad']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['google/gemma-7b', 'meta-llama/Meta-Llama-3-8B'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_3'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1,2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p2_1.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['sciq', 'coqa', 'triviaqa', 'truthfullqa', 'mmlu', 'samsum', 'pubmedqa', 'wmt14_deen', 'gsm8k', 'xsum', 'medquad', 'cnn']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['stabilityai/stablelm-2-12b'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_3'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1,2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p3_1.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['pubmedqa', 'wmt14_deen', 'cnn']\n",
    "\n",
    "layers = {\"google/gemma-7b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(27)])),\n",
    "          \"meta-llama/Meta-Llama-3-8B\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(31)])),\n",
    "          \"stabilityai/stablelm-2-12b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(39)]))}\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3-8B'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_3'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p1_2.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['gsm8k', 'xsum']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    \"subsample_gsm8k_train_dataset\": [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['stabilityai/stablelm-2-12b'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_3'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1,2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p3_2.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['medquad', 'cnn']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    \"subsample_gsm8k_train_dataset\": [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['stabilityai/stablelm-2-12b'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_3'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1,2,3,4]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p3_3.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['sciq', 'coqa', 'triviaqa', 'truthfullqa', 'mmlu', 'samsum', 'pubmedqa', 'wmt14_deen', 'gsm8k', 'xsum', 'medquad', 'cnn']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [-1],\n",
    "    'subsample_background_train_dataset': [10],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3-8B'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_saplma'],\n",
    "    \"subsample_gsm8k_train_dataset\": [2000],\n",
    "    'samples_n': [5],\n",
    "    \"use_truefalse_dataset\": [True]\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p4_1.sh', scripts=\"run_polygraph_3.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['sciq', 'coqa', 'triviaqa', 'truthfullqa', 'mmlu', 'samsum', 'pubmedqa', 'wmt14_deen', 'gsm8k', 'xsum', 'medquad', 'cnn']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3-8B'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_saplma_ds'],\n",
    "    \"subsample_gsm8k_train_dataset\": [2000],\n",
    "    'samples_n': [5],\n",
    "    \"use_truefalse_dataset\": [False],\n",
    "}\n",
    "    \n",
    "cuda_devices = [3]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p4_2.sh', scripts=\"run_polygraph_3.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['sciq', 'coqa', 'triviaqa', 'truthfullqa', 'mmlu']\n",
    "\n",
    "layers = {\"google/gemma-7b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(27)])),\n",
    "          \"meta-llama/Meta-Llama-3-8B\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(31)])),\n",
    "          \"stabilityai/stablelm-2-12b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(39)]))}\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3-8B'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p5_1.sh', scripts=\"run_polygraph_4.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['gsm8k', 'xsum', 'medquad']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3-8B'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p5_2.sh', scripts=\"run_polygraph_4.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['samsum', 'pubmedqa', 'wmt14_deen', 'cnn']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3-8B'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p5_3.sh', scripts=\"run_polygraph_4.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_str_config(config):\n",
    "    config_list = []\n",
    "    config_list.append('ignore_exceptions=False use_density_based_ue=True')\n",
    "    \n",
    "    config_list.append('batch_size={}'.format(config['batch_size']))\n",
    "\n",
    "    if (\"gsm8k\" in config[\"task\"]) or (\"medquad\" in config[\"task\"]) or (\"samsum\" in config[\"task\"]):\n",
    "        config_list.append('subsample_train_dataset={}'.format(config['subsample_gsm8k_train_dataset']))\n",
    "    else:\n",
    "        config_list.append('subsample_train_dataset={}'.format(config['subsample_train_dataset']))\n",
    "    if config.get(\"ablation\", False):\n",
    "        if (\"gsm8k\" in config[\"task\"]) or (\"medquad\" in config[\"task\"]) or (\"samsum\" in config[\"task\"]):\n",
    "            config_list.append('subsample_background_train_dataset={}'.format(config['subsample_gsm8k_train_dataset']))\n",
    "        else:\n",
    "            config_list.append('subsample_background_train_dataset={}'.format(config['subsample_train_dataset']))\n",
    "    else:\n",
    "        config_list.append('subsample_background_train_dataset={}'.format(config['subsample_background_train_dataset']))\n",
    "    config_list.append('subsample_eval_dataset={}'.format(config['subsample_eval_dataset']))\n",
    "    config_list.append('model.path={}'.format(config['model']))\n",
    "    \n",
    "    if (\"gemma\" in config['model']) or (\"mistral\" in config['model'].lower()) or (\"llama-3\" in config['model'].lower()) or (\"stablelm-2\" in config['model'].lower()):\n",
    "        config_list.append('+model.attn_implementation=eager')\n",
    "    if (\"cache_path\" in config.keys()) and config.get(\"ablation\", False):\n",
    "        config_list.append('cache_path={}_{}'.format(config['cache_path'], config['subsample_train_dataset']))\n",
    "    elif (\"cache_path\" in config.keys()):\n",
    "        config_list.append('cache_path={}'.format(config['cache_path']))\n",
    "    if (\"metric_thrs\" in config.keys()):\n",
    "        config_list.append('+metric_thrs={}'.format(config['metric_thrs']))\n",
    "    if (\"layers\" in config.keys()):\n",
    "        config_list.append('+layers={}'.format(config['layers'][config['model']]))\n",
    "    if (\"samples_n\" in config.keys()):\n",
    "        config_list.append('+generation_params.samples_n={}'.format(config['samples_n']))\n",
    "    if (\"baselines\" in config.keys()):\n",
    "        if config['baselines'] == \"all\":\n",
    "            config_list.append('+run_baselines=True')\n",
    "            config_list.append('+md_device=cuda')\n",
    "            config_list.append('+run_proposed_methods=True')\n",
    "            config_list.append('+clean_md_device=cuda')\n",
    "        elif config['baselines']:\n",
    "            config_list.append('+run_baselines=True')\n",
    "            config_list.append('+md_device=cuda')\n",
    "        else:\n",
    "            config_list.append('+run_proposed_methods=True')\n",
    "            config_list.append('+run_layerwise_methods=True')\n",
    "            config_list.append('+clean_md_device=cuda')\n",
    "            config_list.append('+md_device=cuda')\n",
    "            config_list.append('+run_eigenscore=False')\n",
    "                \n",
    "    if (\"use_truefalse_dataset\" in config.keys()):\n",
    "        config_list.append('+use_truefalse_dataset={}'.format(config['use_truefalse_dataset']))\n",
    "        if (config[\"use_truefalse_dataset\"]):\n",
    "            config_list.append('train_dataset=../data/publicDataset/truefalsedata.csv +train_text_column=statement +train_label_column=label')\n",
    "    return config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = {\"google/gemma-2-9b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(41)])),\n",
    "          \"meta-llama/Meta-Llama-3.1-8B\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(31)])),\n",
    "          \"stabilityai/stablelm-2-12b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(39)])),\n",
    "          \"Qwen/Qwen2.5-7B\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(27)])),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['sciq', 'coqa', 'triviaqa', 'mmlu', 'truthfullqa', 'samsum']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"Qwen/Qwen2.5-7B\"],# \"stabilityai/stablelm-2-12b\"],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'baselines': [\"all\"],#[False, True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_final_1.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['gsm8k', 'medquad', 'xsum']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"Qwen/Qwen2.5-7B\"],# \"stabilityai/stablelm-2-12b\"],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'baselines': [\"all\"],#[False, True],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_final_2.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['pubmedqa', 'cnn', \"wmt19_deen\"]# 'wmt14_fren', \n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"Qwen/Qwen2.5-7B\"],# \"stabilityai/stablelm-2-12b\"],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'baselines': [\"all\"],#False, True],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_final_3.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['pubmedqa', 'cnn']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"google/gemma-2-9b\"],# \"stabilityai/stablelm-2-12b\"],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'baselines': [\"all\"],#False, True],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_final_3_2.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['medquad', 'gsm8k']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"google/gemma-2-9b\"],# \"stabilityai/stablelm-2-12b\"],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'baselines': [\"all\"],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1,2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_final_3_3.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blackbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['sciq', 'truthfullqa', 'samsum', 'gsm8k', 'cnn', 'triviaqa', 'mmlu']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_gsm8k_train_dataset': [1000],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\"],# \"stabilityai/stablelm-2-12b\"],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'baselines': [False],#[False, True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = ['0,1']\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_proxy_1.sh', scripts=\"run_polygraph_test.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train size ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['sciq']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"google/gemma-2-9b\"],# \"stabilityai/stablelm-2-12b\"],\n",
    "    'subsample_train_dataset': [100, 200, 500, 1000, 2000],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_ablation'],\n",
    "    'baselines': [False],\n",
    "    'ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_1.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['truthfullqa']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"google/gemma-2-9b\"],# \"stabilityai/stablelm-2-12b\"],\n",
    "    'subsample_train_dataset': [100, 200, 500],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_ablation'],\n",
    "    'baselines': [False],\n",
    "    'ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_1_1.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['mmlu', 'cnn']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"google/gemma-2-9b\"],# \"stabilityai/stablelm-2-12b\"],\n",
    "    'subsample_train_dataset': [100, 200, 500, 1000, 2000],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'baselines': [False],\n",
    "    'ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_2.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['medquad']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"google/gemma-2-9b\"],# \"stabilityai/stablelm-2-12b\"],\n",
    "    'subsample_gsm8k_train_dataset': [100, 200, 500, 1000, 2000],\n",
    "    'subsample_train_dataset': [100],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'baselines': [False],\n",
    "    'ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_3.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['gsm8k']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"google/gemma-2-9b\"],# \"stabilityai/stablelm-2-12b\"],\n",
    "    'subsample_gsm8k_train_dataset': [100, 200, 500, 1000, 2000],\n",
    "    'subsample_train_dataset': [100],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'baselines': [False],\n",
    "    'ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_4.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['samsum']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\"],# \"stabilityai/stablelm-2-12b\"],\n",
    "    'subsample_gsm8k_train_dataset': [100, 200, 500, 1000],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'baselines': [False],\n",
    "    'ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_5.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def generate_train_str_config(config, task_name):\n",
    "    config_list = []\n",
    "    config_list.append('ignore_exceptions=False use_density_based_ue=True')\n",
    "    \n",
    "    config_list.append('batch_size={}'.format(config['batch_size']))\n",
    "    config_list.append('train_test_split=False')\n",
    "    config_list.append('subsample_train_dataset={}'.format(config['subsample_train_dataset']))\n",
    "    config_list.append('subsample_background_train_dataset={}'.format(config['subsample_background_train_dataset']))\n",
    "    config_list.append('subsample_eval_dataset={}'.format(config['subsample_eval_dataset']))\n",
    "    config_list.append('model.path={}'.format(config['model']))\n",
    "    if (\"gemma\" in config['model']) or (\"mistral\" in config['model'].lower()) or (\"llama-3\" in config['model'].lower()) or (\"stablelm-2\" in config['model'].lower()):\n",
    "        config_list.append('+model.attn_implementation=eager')\n",
    "    if (\"cache_path\" in config.keys()) and not config.get(\"upd_path\", False):\n",
    "        config_list.append('cache_path={}'.format(config['cache_path']))\n",
    "    if (\"samples_n\" in config.keys()):\n",
    "        config_list.append('+generation_params.samples_n={}'.format(config['samples_n']))\n",
    "    if (\"metric_thrs\" in config.keys()):\n",
    "        config_list.append('+metric_thrs={}'.format(config['metric_thrs']))\n",
    "    if (\"layers\" in config.keys()):\n",
    "        config_list.append('+layers={}'.format(config['layers'][config['model']]))\n",
    "    if config.get(\"generalization\", False):\n",
    "        try:\n",
    "            ood_cfg = gen_tasks[task_name][config[\"exp_idx\"]]\n",
    "        except:\n",
    "            return \"\"\n",
    "        for i, ds in enumerate(ood_cfg):\n",
    "            if (\"cache_path\" in config.keys()) and config.get(\"upd_path\", False):\n",
    "                config_list.append('cache_path={}_on_{}'.format(config['cache_path'], ds))\n",
    "            with open(f\"../configs/polygraph_eval_{ds}.yaml\") as stream:\n",
    "                gen_config = yaml.safe_load(stream)\n",
    "            config_list.append('+max_new_tokens_{}={}'.format(i+1, gen_config['max_new_tokens']))\n",
    "            config_list.append('+train_dataset_{}=\\\"{}\\\"'.format(i+1, gen_config['dataset']))\n",
    "            config_list.append('+train_text_column_{}={}'.format(i+1, gen_config['text_column']))\n",
    "            config_list.append('+train_label_column_{}={}'.format(i+1, gen_config['label_column']))\n",
    "            config_list.append('+train_prompt_{}=\\\"{}\\\"'.format(i+1, gen_config['prompt']))\n",
    "            \n",
    "            config_list[-1] = config_list[-1].replace(\"\\n\", \"\\\\n\")\n",
    "            config_list[-1] = config_list[-1].replace(\"$\", \"\\\\$\")\n",
    "            config_list[-1] = config_list[-1].replace(\"'s\", \" is\")\n",
    "            config_list[-1] = config_list[-1].replace(\"(\", \"\\\\(\")\n",
    "            config_list[-1] = config_list[-1].replace(\")\", \"\\\\)\")\n",
    "            config_list[-1] = config_list[-1].replace(\"}\", \"\\\\}\")\n",
    "            config_list[-1] = config_list[-1].replace(\"{\", \"\\\\{\")\n",
    "            config_list[-1] = config_list[-1].replace(\"]\", \"\\\\]\")\n",
    "            config_list[-1] = config_list[-1].replace(\"[\", \"\\\\[\")\n",
    "            config_list[-1] = config_list[-1].replace(\",\", \"\\\\,\")\n",
    "            config_list[-1] = config_list[-1].replace(\"=\", \"\\\\=\")\n",
    "            # config_list[-1] = config_list[-1].replace(\"+\", \"\\\\+\")\n",
    "            config_list.append('+train_split_{}={}'.format(i+1, gen_config['train_split']))\n",
    "\n",
    "            if \"description\" in gen_config.keys():\n",
    "                config_list.append(\"+train_description_{}=\\\"{}\\\"\".format(i+1, gen_config['description']))\n",
    "                config_list[-1] = config_list[-1].replace(\"\\n\", \"\\\\n\")\n",
    "                config_list[-1] = config_list[-1].replace(\"'s\", \" is\")\n",
    "                config_list[-1] = config_list[-1].replace(\"(\", \"\\\\(\")\n",
    "                config_list[-1] = config_list[-1].replace(\")\", \"\\\\)\")\n",
    "                config_list[-1] = config_list[-1].replace(\"}\", \"\\\\}\")\n",
    "                config_list[-1] = config_list[-1].replace(\"{\", \"\\\\{\")\n",
    "                config_list[-1] = config_list[-1].replace(\",\", \"\\\\,\")\n",
    "                config_list[-1] = config_list[-1].replace(\"$\", \"\\\\$\")\n",
    "                config_list[-1] = config_list[-1].replace(\"=\", \"\\\\=\")\n",
    "                config_list[-1] = config_list[-1].replace(\"]\", \"\\\\]\")\n",
    "                config_list[-1] = config_list[-1].replace(\"[\", \"\\\\[\")\n",
    "                # config_list[-1] = config_list[-1].replace(\"+\", \"\\\\+\")\n",
    "                \n",
    "            if \"few_shot_split\" in gen_config.keys():\n",
    "                config_list.append('+few_shot_split_{}={}'.format(i+1, gen_config['few_shot_split']))\n",
    "            if \"n_shot\" in gen_config.keys():\n",
    "                config_list.append('+train_n_shot_{}={}'.format(i+1, gen_config['n_shot']))\n",
    "    if (\"baselines\" in config.keys()):\n",
    "        if config['baselines'] == \"all\":\n",
    "            config_list.append('+run_baselines=False')\n",
    "            config_list.append('+run_eigenscore=False')\n",
    "            config_list.append('+md_device=cuda')\n",
    "            config_list.append('+run_proposed_methods=True')\n",
    "            config_list.append('+run_layerwise_methods=True')\n",
    "            config_list.append('+clean_md_device=cuda')\n",
    "        elif config['baselines']:\n",
    "            config_list.append('+run_baselines=False')\n",
    "            config_list.append('+run_eigenscore=False')\n",
    "            config_list.append('+run_layerwise_methods=True')\n",
    "            config_list.append('+md_device=cuda')\n",
    "        else:\n",
    "            config_list.append('+run_proposed_methods=True')\n",
    "            config_list.append('+clean_md_device=cuda')\n",
    "    if \"is_ood\" in config.keys():\n",
    "        config_list.append('+is_ood={}'.format(config['is_ood']))\n",
    "        \n",
    "    return config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bash(configs, cuda_devices, tasks, generate_func, script_name=\"polygraph_eval\", filename='', n_gpus=1):\n",
    "    full_config = 'cd ../'\n",
    "    j = 0\n",
    "    print(tasks)\n",
    "    n_devices = len(cuda_devices)\n",
    "    for i, mc_configs in enumerate(configs):\n",
    "        for conf in expand_config(mc_configs):\n",
    "            for task_name in tasks:\n",
    "                \n",
    "                if (n_gpus == 1) or ((task_name not in [\"gsm8k\", \"xsum\", \"medquad\"]) and ((\"7b\" in conf[\"model\"]) or (\"8b\" not in conf[\"model\"]))):\n",
    "                    base_arg = f'CUDA_VISIBLE_DEVICES={cuda_devices[j%n_devices]} HYDRA_CONFIG=./configs/polygraph_eval_{task_name}.yaml python run_polygraph.py'\n",
    "                else:\n",
    "                    base_arg = f'CUDA_VISIBLE_DEVICES={cuda_devices[j%n_devices]},{cuda_devices[(j+1)%n_devices]} HYDRA_CONFIG=./configs/polygraph_eval_{task_name}.yaml python run_polygraph.py'\n",
    "                    j+=1\n",
    "                    \n",
    "                new_task = copy.deepcopy(base_arg)\n",
    "                args = ' '.join(generate_func[i](conf, task_name))\n",
    "                if not len(args.strip()):\n",
    "                    continue\n",
    "                new_task += f' {args}'\n",
    "                if (j+1)%n_devices!=0: \n",
    "                    new_task += ' &'\n",
    "                else:\n",
    "                    new_task += '\\nwait'\n",
    "                full_config += '\\n' + new_task if len(full_config) else new_task\n",
    "                j+=1\n",
    "                \n",
    "    with open (f'../scripts/{filename}', 'w') as rsh:\n",
    "        rsh.write(full_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_ts = ['samsum', 'xsum', 'cnn']\n",
    "datasets_tr = ['wmt14_fren', \"wmt19_deen\"]\n",
    "datasets_qa_s = ['sciq', 'coqa', 'triviaqa', 'mmlu']\n",
    "# datasets_qa_l = ['truthfullqa', 'pubmedqa', 'medquad']\n",
    "datasets_qa_l = ['truthfullqa', 'pubmedqa']\n",
    "all_tasks = [datasets_ts, datasets_qa_s, datasets_qa_l]#, datasets_tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'truthfullqa': [['samsum', 'xsum', 'cnn', 'sciq', 'coqa', 'triviaqa', 'mmlu', 'pubmedqa']], 'samsum': [['xsum', 'cnn', 'sciq', 'coqa', 'triviaqa', 'mmlu', 'truthfullqa', 'pubmedqa']]}\n",
      "['truthfullqa', 'samsum']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 1\n",
    "tasks = ['truthfullqa', 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    all_tasks_i = [x for x in np.concatenate(all_tasks) if x != task] \n",
    "    for i, ds in enumerate(all_tasks_i):\n",
    "        ds_exps.append(ds)\n",
    "    gen_tasks[task].append(ds_exps)\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [1000],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B'],\n",
    "    'cache_path': ['./workdir/gen_output_loo_new'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps)),\n",
    "    \"is_ood\": [True],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_v2_all.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mmlu': [['samsum', 'xsum', 'cnn', 'sciq', 'coqa', 'triviaqa', 'truthfullqa', 'pubmedqa', 'medquad']], 'truthfullqa': [['samsum', 'xsum', 'cnn', 'sciq', 'coqa', 'triviaqa', 'mmlu', 'pubmedqa', 'medquad']], 'samsum': [['xsum', 'cnn', 'sciq', 'coqa', 'triviaqa', 'mmlu', 'truthfullqa', 'pubmedqa', 'medquad']], 'sciq': [['samsum', 'xsum', 'cnn', 'coqa', 'triviaqa', 'mmlu', 'truthfullqa', 'pubmedqa', 'medquad']]}\n",
      "['mmlu', 'truthfullqa', 'samsum', 'sciq']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 1\n",
    "tasks = ['mmlu', 'truthfullqa', 'samsum', 'sciq']#, 'cnn', 'samsum']#, 'medquad', 'xsum', 'pubmedqa', 'wmt14_fren', 'cnn', \"wmt19_deen\", 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    all_tasks_i = [x for x in np.concatenate(all_tasks) if x != task] \n",
    "    for i, ds in enumerate(all_tasks_i):\n",
    "        ds_exps.append(ds)\n",
    "    gen_tasks[task].append(ds_exps)\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [400],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B'],\n",
    "    'cache_path': ['./workdir/gen_output_loo_new'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps)),\n",
    "    \"is_ood\": [True],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_v2_1.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mmlu': [['sciq', 'coqa', 'triviaqa']], 'truthfullqa': [['pubmedqa', 'medquad']], 'samsum': [['xsum', 'cnn']], 'sciq': [['coqa', 'triviaqa', 'mmlu']]}\n",
      "['mmlu', 'truthfullqa', 'samsum', 'sciq']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 1\n",
    "tasks = ['mmlu', 'truthfullqa', 'samsum', 'sciq']#, 'cnn', 'samsum']#, 'medquad', 'xsum', 'pubmedqa', 'wmt14_fren', 'cnn', \"wmt19_deen\", 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    for i, ds_tasks in enumerate(all_tasks):\n",
    "        if task in ds_tasks:\n",
    "            for ds in ds_tasks:\n",
    "                if ds != task:\n",
    "                    ds_exps.append(ds)\n",
    "    gen_tasks[task].append(ds_exps)\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [400],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B'],\n",
    "    'cache_path': ['./workdir/gen_output_loo_new'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps)),\n",
    "    \"is_ood\": [True],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_v2_2.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mmlu': [['sciq', 'coqa', 'triviaqa']], 'truthfullqa': [['pubmedqa', 'medquad']], 'samsum': [['xsum', 'cnn']], 'sciq': [['coqa', 'triviaqa', 'mmlu']]}\n",
      "['mmlu', 'truthfullqa', 'samsum', 'sciq']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 1\n",
    "tasks = ['mmlu', 'truthfullqa', 'samsum', 'sciq']#, 'cnn', 'samsum']#, 'medquad', 'xsum', 'pubmedqa', 'wmt14_fren', 'cnn', \"wmt19_deen\", 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    for i, ds_tasks in enumerate(all_tasks):\n",
    "        if task in ds_tasks:\n",
    "            for ds in ds_tasks:\n",
    "                if ds != task:\n",
    "                    ds_exps.append(ds)\n",
    "    gen_tasks[task].append(ds_exps)\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [1000],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B'],\n",
    "    'cache_path': ['./workdir/gen_output_loo_new'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps)),\n",
    "    \"is_ood\": [True],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_v2_3.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mmlu': [['sciq'], ['coqa'], ['triviaqa']], 'truthfullqa': [['pubmedqa'], ['medquad']], 'samsum': [['xsum'], ['cnn']], 'sciq': [['coqa'], ['triviaqa'], ['mmlu']]}\n",
      "['mmlu', 'truthfullqa', 'samsum', 'sciq']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 3\n",
    "tasks = ['mmlu', 'truthfullqa', 'samsum', 'sciq']#, 'cnn', 'samsum']#, 'medquad', 'xsum', 'pubmedqa', 'wmt14_fren', 'cnn', \"wmt19_deen\", 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    for i, ds_tasks in enumerate(all_tasks):\n",
    "        if task in ds_tasks:\n",
    "            for ds in ds_tasks:\n",
    "                if ds != task:\n",
    "                    # ds_exps.append(ds)\n",
    "                    gen_tasks[task].append([ds])\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B'],\n",
    "    'cache_path': ['./workdir/gen_output_loo_new'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps)),\n",
    "    \"is_ood\": [True],\n",
    "    \"upd_path\": [True]\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_v2_4.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mmlu': [['samsum', 'xsum', 'cnn', 'sciq', 'coqa', 'triviaqa', 'truthfullqa', 'pubmedqa', 'medquad']]}\n",
      "['mmlu']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 1\n",
    "tasks = ['mmlu']#, 'truthfullqa', 'samsum', 'cnn', 'medquad']#, 'cnn', 'samsum']#, 'medquad', 'xsum', 'pubmedqa', 'wmt14_fren', 'cnn', \"wmt19_deen\", 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    # for i, ds_tasks in enumerate(all_tasks):\n",
    "    #     if task in ds_tasks:\n",
    "    #         for ds in ds_tasks:\n",
    "    #             if ds != task:\n",
    "    #                 ds_exps.append(ds)\n",
    "    # gen_tasks[task].append(ds_exps)\n",
    "\n",
    "    ds_exps = []\n",
    "    all_tasks_i = [x for x in np.concatenate(all_tasks) if x != task] \n",
    "    for i, ds in enumerate(all_tasks_i):\n",
    "        ds_exps.append(ds)\n",
    "    gen_tasks[task].append(ds_exps)\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [400],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B', \"google/gemma-2-9b\"],\n",
    "    'cache_path': ['./workdir/gen_output_loo_final'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps)),\n",
    "    \"is_ood\": [True],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_p1_upd1.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sciq': [['samsum', 'xsum', 'cnn', 'coqa', 'triviaqa', 'mmlu', 'truthfullqa', 'pubmedqa', 'medquad']]}\n",
      "['sciq']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 1\n",
    "tasks = ['sciq']#, 'truthfullqa', 'samsum', 'cnn', 'medquad']#, 'cnn', 'samsum']#, 'medquad', 'xsum', 'pubmedqa', 'wmt14_fren', 'cnn', \"wmt19_deen\", 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    # for i, ds_tasks in enumerate(all_tasks):\n",
    "    #     if task in ds_tasks:\n",
    "    #         for ds in ds_tasks:\n",
    "    #             if ds != task:\n",
    "    #                 ds_exps.append(ds)\n",
    "    # gen_tasks[task].append(ds_exps)\n",
    "\n",
    "    ds_exps = []\n",
    "    all_tasks_i = [x for x in np.concatenate(all_tasks) if x != task] \n",
    "    for i, ds in enumerate(all_tasks_i):\n",
    "        ds_exps.append(ds)\n",
    "    gen_tasks[task].append(ds_exps)\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [400],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B', \"google/gemma-2-9b\"],\n",
    "    'cache_path': ['./workdir/gen_output_loo_final'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps)),\n",
    "    \"is_ood\": [True],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_p1_upd2.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'medquad': [['samsum', 'xsum', 'cnn', 'sciq', 'coqa', 'triviaqa', 'mmlu', 'truthfullqa', 'pubmedqa']]}\n",
      "['medquad']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 1\n",
    "tasks = ['medquad']#, 'cnn', 'samsum']#, 'medquad', 'xsum', 'pubmedqa', 'wmt14_fren', 'cnn', \"wmt19_deen\", 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    # for i, ds_tasks in enumerate(all_tasks):\n",
    "    #     if task in ds_tasks:\n",
    "    #         for ds in ds_tasks:\n",
    "    #             if ds != task:\n",
    "    #                 ds_exps.append(ds)\n",
    "    # gen_tasks[task].append(ds_exps)\n",
    "\n",
    "    ds_exps = []\n",
    "    all_tasks_i = [x for x in np.concatenate(all_tasks) if x != task] \n",
    "    for i, ds in enumerate(all_tasks_i):\n",
    "        ds_exps.append(ds)\n",
    "    gen_tasks[task].append(ds_exps)\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [100],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B', \"google/gemma-2-9b\"],\n",
    "    'cache_path': ['./workdir/gen_output_loo_final_2'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps))\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_p1_1.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mmlu': [['samsum', 'xsum', 'cnn', 'sciq', 'coqa', 'triviaqa', 'truthfullqa', 'pubmedqa', 'medquad']], 'sciq': [['samsum', 'xsum', 'cnn', 'coqa', 'triviaqa', 'mmlu', 'truthfullqa', 'pubmedqa', 'medquad']], 'samsum': [['xsum', 'cnn', 'sciq', 'coqa', 'triviaqa', 'mmlu', 'truthfullqa', 'pubmedqa', 'medquad']]}\n",
      "['mmlu', 'sciq', 'samsum']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 1\n",
    "tasks = ['mmlu', 'sciq', 'samsum']#, 'cnn', 'samsum']#, 'medquad', 'xsum', 'pubmedqa', 'wmt14_fren', 'cnn', \"wmt19_deen\", 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    # for i, ds_tasks in enumerate(all_tasks):\n",
    "    #     if task in ds_tasks:\n",
    "    #         for ds in ds_tasks:\n",
    "    #             if ds != task:\n",
    "    #                 ds_exps.append(ds)\n",
    "    # gen_tasks[task].append(ds_exps)\n",
    "\n",
    "    ds_exps = []\n",
    "    all_tasks_i = [x for x in np.concatenate(all_tasks) if x != task] \n",
    "    for i, ds in enumerate(all_tasks_i):\n",
    "        ds_exps.append(ds)\n",
    "    gen_tasks[task].append(ds_exps)\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [100],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B', \"google/gemma-2-9b\"],\n",
    "    'cache_path': ['./workdir/gen_output_loo_final_2'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps))\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_p1_2.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gsm8k': [['samsum', 'xsum', 'cnn', 'sciq', 'coqa', 'triviaqa', 'mmlu', 'truthfullqa', 'pubmedqa', 'medquad']]}\n",
      "['gsm8k']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 1\n",
    "tasks = ['gsm8k']#, 'cnn', 'samsum']#, 'medquad', 'xsum', 'pubmedqa', 'wmt14_fren', 'cnn', \"wmt19_deen\", 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    # for i, ds_tasks in enumerate(all_tasks):\n",
    "    #     if task in ds_tasks:\n",
    "    #         for ds in ds_tasks:\n",
    "    #             if ds != task:\n",
    "    #                 ds_exps.append(ds)\n",
    "    # gen_tasks[task].append(ds_exps)\n",
    "\n",
    "    ds_exps = []\n",
    "    all_tasks_i = [x for x in np.concatenate(all_tasks) if x != task] \n",
    "    for i, ds in enumerate(all_tasks_i):\n",
    "        ds_exps.append(ds)\n",
    "    gen_tasks[task].append(ds_exps)\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [400],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B', \"google/gemma-2-9b\"],\n",
    "    'cache_path': ['./workdir/gen_output_loo'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps))\n",
    "}\n",
    "    \n",
    "cuda_devices = [2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_p2.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def generate_train_str_config(config, task_name):\n",
    "    config_list = []\n",
    "    config_list.append('ignore_exceptions=False use_density_based_ue=True')\n",
    "    \n",
    "    config_list.append('batch_size={}'.format(config['batch_size']))\n",
    "    config_list.append('train_test_split=False')\n",
    "    config_list.append('subsample_train_dataset={}'.format(config['subsample_train_dataset']))\n",
    "    config_list.append('subsample_background_train_dataset={}'.format(config['subsample_background_train_dataset']))\n",
    "    config_list.append('subsample_eval_dataset={}'.format(config['subsample_eval_dataset']))\n",
    "    config_list.append('model.path={}'.format(config['model']))\n",
    "    if (\"gemma\" in config['model']) or (\"mistral\" in config['model'].lower()) or (\"llama-3\" in config['model'].lower()) or (\"stablelm-2\" in config['model'].lower()):\n",
    "        config_list.append('+model.attn_implementation=eager')\n",
    "    if (\"cache_path\" in config.keys()) and not config.get(\"upd_path\", False):\n",
    "        config_list.append('cache_path={}'.format(config['cache_path']))\n",
    "    if (\"samples_n\" in config.keys()):\n",
    "        config_list.append('+generation_params.samples_n={}'.format(config['samples_n']))\n",
    "    if (\"metric_thrs\" in config.keys()):\n",
    "        config_list.append('+metric_thrs={}'.format(config['metric_thrs']))\n",
    "    if (\"layers\" in config.keys()):\n",
    "        config_list.append('+layers={}'.format(config['layers'][config['model']]))\n",
    "    if config.get(\"generalization\", False):\n",
    "        try:\n",
    "            ood_cfg = train_exps[task_name][config[\"exp_idx\"]]\n",
    "        except:\n",
    "            return \"\"\n",
    "        for i, ds in enumerate(ood_cfg):\n",
    "            if (\"cache_path\" in config.keys()) and config.get(\"upd_path\", False):\n",
    "                config_list.append('cache_path={}_on_{}'.format(config['cache_path'], ds))\n",
    "            with open(f\"../configs/polygraph_eval_{ds}.yaml\") as stream:\n",
    "                gen_config = yaml.safe_load(stream)\n",
    "            config_list.append('+max_new_tokens_{}={}'.format(i+1, gen_config['max_new_tokens']))\n",
    "            config_list.append('+train_dataset_{}=\\\"{}\\\"'.format(i+1, gen_config['dataset']))\n",
    "            config_list.append('+train_text_column_{}={}'.format(i+1, gen_config['text_column']))\n",
    "            config_list.append('+train_label_column_{}={}'.format(i+1, gen_config['label_column']))\n",
    "            config_list.append('+train_prompt_{}=\\\"{}\\\"'.format(i+1, gen_config['prompt']))\n",
    "            \n",
    "            config_list[-1] = config_list[-1].replace(\"\\n\", \"\\\\n\")\n",
    "            config_list[-1] = config_list[-1].replace(\"$\", \"\\\\$\")\n",
    "            config_list[-1] = config_list[-1].replace(\"'s\", \" is\")\n",
    "            config_list[-1] = config_list[-1].replace(\"(\", \"\\\\(\")\n",
    "            config_list[-1] = config_list[-1].replace(\")\", \"\\\\)\")\n",
    "            config_list[-1] = config_list[-1].replace(\"}\", \"\\\\}\")\n",
    "            config_list[-1] = config_list[-1].replace(\"{\", \"\\\\{\")\n",
    "            config_list[-1] = config_list[-1].replace(\"]\", \"\\\\]\")\n",
    "            config_list[-1] = config_list[-1].replace(\"[\", \"\\\\[\")\n",
    "            config_list[-1] = config_list[-1].replace(\",\", \"\\\\,\")\n",
    "            config_list[-1] = config_list[-1].replace(\"=\", \"\\\\=\")\n",
    "            # config_list[-1] = config_list[-1].replace(\"+\", \"\\\\+\")\n",
    "            config_list.append('+train_split_{}={}'.format(i+1, gen_config['train_split']))\n",
    "\n",
    "            if \"description\" in gen_config.keys():\n",
    "                config_list.append(\"+train_description_{}=\\\"{}\\\"\".format(i+1, gen_config['description']))\n",
    "                config_list[-1] = config_list[-1].replace(\"\\n\", \"\\\\n\")\n",
    "                config_list[-1] = config_list[-1].replace(\"'s\", \" is\")\n",
    "                config_list[-1] = config_list[-1].replace(\"(\", \"\\\\(\")\n",
    "                config_list[-1] = config_list[-1].replace(\")\", \"\\\\)\")\n",
    "                config_list[-1] = config_list[-1].replace(\"}\", \"\\\\}\")\n",
    "                config_list[-1] = config_list[-1].replace(\"{\", \"\\\\{\")\n",
    "                config_list[-1] = config_list[-1].replace(\",\", \"\\\\,\")\n",
    "                config_list[-1] = config_list[-1].replace(\"$\", \"\\\\$\")\n",
    "                config_list[-1] = config_list[-1].replace(\"=\", \"\\\\=\")\n",
    "                config_list[-1] = config_list[-1].replace(\"]\", \"\\\\]\")\n",
    "                config_list[-1] = config_list[-1].replace(\"[\", \"\\\\[\")\n",
    "                # config_list[-1] = config_list[-1].replace(\"+\", \"\\\\+\")\n",
    "                \n",
    "            if \"few_shot_split\" in gen_config.keys():\n",
    "                config_list.append('+few_shot_split_{}={}'.format(i+1, gen_config['few_shot_split']))\n",
    "            if \"n_shot\" in gen_config.keys():\n",
    "                config_list.append('+train_n_shot_{}={}'.format(i+1, gen_config['n_shot']))\n",
    "\n",
    "        try:\n",
    "            ood_cfg = test_exps[task_name][config[\"exp_idx\"]]\n",
    "        except:\n",
    "            return \"\"\n",
    "        for i, ds in enumerate(ood_cfg):\n",
    "            with open(f\"../configs/polygraph_eval_{ds}.yaml\") as stream:\n",
    "                gen_config = yaml.safe_load(stream)\n",
    "            config_list.append('+eval_max_new_tokens_{}={}'.format(i+1, gen_config['max_new_tokens']))\n",
    "            config_list.append('+eval_dataset_{}=\\\"{}\\\"'.format(i+1, gen_config['dataset']))\n",
    "            config_list.append('+eval_text_column_{}={}'.format(i+1, gen_config['text_column']))\n",
    "            config_list.append('+eval_label_column_{}={}'.format(i+1, gen_config['label_column']))\n",
    "            config_list.append('+eval_prompt_{}=\\\"{}\\\"'.format(i+1, gen_config['prompt']))\n",
    "            \n",
    "            config_list[-1] = config_list[-1].replace(\"\\n\", \"\\\\n\")\n",
    "            config_list[-1] = config_list[-1].replace(\"$\", \"\\\\$\")\n",
    "            config_list[-1] = config_list[-1].replace(\"'s\", \" is\")\n",
    "            config_list[-1] = config_list[-1].replace(\"(\", \"\\\\(\")\n",
    "            config_list[-1] = config_list[-1].replace(\")\", \"\\\\)\")\n",
    "            config_list[-1] = config_list[-1].replace(\"}\", \"\\\\}\")\n",
    "            config_list[-1] = config_list[-1].replace(\"{\", \"\\\\{\")\n",
    "            config_list[-1] = config_list[-1].replace(\"]\", \"\\\\]\")\n",
    "            config_list[-1] = config_list[-1].replace(\"[\", \"\\\\[\")\n",
    "            config_list[-1] = config_list[-1].replace(\",\", \"\\\\,\")\n",
    "            config_list[-1] = config_list[-1].replace(\"=\", \"\\\\=\")\n",
    "            # config_list[-1] = config_list[-1].replace(\"+\", \"\\\\+\")\n",
    "            config_list.append('+eval_split_{}={}'.format(i+1, gen_config['train_split']))\n",
    "\n",
    "            if \"description\" in gen_config.keys():\n",
    "                config_list.append(\"+eval_description_{}=\\\"{}\\\"\".format(i+1, gen_config['description']))\n",
    "                config_list[-1] = config_list[-1].replace(\"\\n\", \"\\\\n\")\n",
    "                config_list[-1] = config_list[-1].replace(\"'s\", \" is\")\n",
    "                config_list[-1] = config_list[-1].replace(\"(\", \"\\\\(\")\n",
    "                config_list[-1] = config_list[-1].replace(\")\", \"\\\\)\")\n",
    "                config_list[-1] = config_list[-1].replace(\"}\", \"\\\\}\")\n",
    "                config_list[-1] = config_list[-1].replace(\"{\", \"\\\\{\")\n",
    "                config_list[-1] = config_list[-1].replace(\",\", \"\\\\,\")\n",
    "                config_list[-1] = config_list[-1].replace(\"$\", \"\\\\$\")\n",
    "                config_list[-1] = config_list[-1].replace(\"=\", \"\\\\=\")\n",
    "                config_list[-1] = config_list[-1].replace(\"]\", \"\\\\]\")\n",
    "                config_list[-1] = config_list[-1].replace(\"[\", \"\\\\[\")\n",
    "                # config_list[-1] = config_list[-1].replace(\"+\", \"\\\\+\")\n",
    "                \n",
    "            if \"few_shot_split\" in gen_config.keys():\n",
    "                config_list.append('+eval_few_shot_split_{}={}'.format(i+1, gen_config['few_shot_split']))\n",
    "            if \"n_shot\" in gen_config.keys():\n",
    "                config_list.append('+eval_n_shot_{}={}'.format(i+1, gen_config['n_shot']))\n",
    "    if (\"baselines\" in config.keys()):\n",
    "        if config['baselines'] == \"all\":\n",
    "            config_list.append('+run_baselines=False')\n",
    "            config_list.append('+run_eigenscore=False')\n",
    "            config_list.append('+md_device=cuda')\n",
    "            config_list.append('+run_proposed_methods=True')\n",
    "            config_list.append('+run_layerwise_methods=True')\n",
    "            config_list.append('+clean_md_device=cuda')\n",
    "        elif config['baselines']:\n",
    "            config_list.append('+run_baselines=False')\n",
    "            config_list.append('+run_eigenscore=False')\n",
    "            config_list.append('+run_layerwise_methods=True')\n",
    "            config_list.append('+md_device=cuda')\n",
    "        else:\n",
    "            config_list.append('+run_proposed_methods=True')\n",
    "            config_list.append('+clean_md_device=cuda')\n",
    "    if \"is_ood\" in config.keys():\n",
    "        config_list.append('+is_ood={}'.format(config['is_ood']))\n",
    "        \n",
    "    return config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bash(configs, cuda_devices, tasks, generate_func, script_name=\"polygraph_eval\", filename='', n_gpus=1):\n",
    "    full_config = 'cd ../'\n",
    "    j = 0\n",
    "    print(tasks)\n",
    "    n_devices = len(cuda_devices)\n",
    "    for i, mc_configs in enumerate(configs):\n",
    "        for conf in expand_config(mc_configs):\n",
    "            for task_name in tasks:\n",
    "                \n",
    "                if (n_gpus == 1) or ((task_name not in [\"gsm8k\", \"xsum\", \"medquad\"]) and ((\"7b\" in conf[\"model\"]) or (\"8b\" not in conf[\"model\"]))):\n",
    "                    base_arg = f'CUDA_VISIBLE_DEVICES={cuda_devices[j%n_devices]} HYDRA_CONFIG=./configs/polygraph_eval_{task_name}.yaml python run_polygraph.py'\n",
    "                else:\n",
    "                    base_arg = f'CUDA_VISIBLE_DEVICES={cuda_devices[j%n_devices]},{cuda_devices[(j+1)%n_devices]} HYDRA_CONFIG=./configs/polygraph_eval_{task_name}.yaml python run_polygraph.py'\n",
    "                    j+=1\n",
    "                    \n",
    "                new_task = copy.deepcopy(base_arg)\n",
    "                args = ' '.join(generate_func[i](conf, task_name))\n",
    "                if not len(args.strip()):\n",
    "                    continue\n",
    "                new_task += f' {args}'\n",
    "                if (j+1)%n_devices!=0: \n",
    "                    new_task += ' &'\n",
    "                else:\n",
    "                    new_task += '\\nwait'\n",
    "                full_config += '\\n' + new_task if len(full_config) else new_task\n",
    "                j+=1\n",
    "                \n",
    "    with open (f'../scripts/{filename}', 'w') as rsh:\n",
    "        rsh.write(full_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_ts = ['samsum', 'xsum', 'cnn']\n",
    "datasets_qa_s = ['sciq', 'coqa', 'triviaqa', 'mmlu']\n",
    "datasets_qa_l = ['truthfullqa', 'pubmedqa', 'medquad']\n",
    "\n",
    "np.random.seed(7777)\n",
    "\n",
    "train_exps = {}\n",
    "test_exps = {}\n",
    "n_splits = 3\n",
    "for split in range(n_splits):\n",
    "    all_tasks_train = []\n",
    "    all_tasks_test = []\n",
    "    n_train = np.random.choice([1,2])\n",
    "    ds1 = np.random.choice(datasets_ts, size=n_train, replace=False)\n",
    "    all_tasks_train.extend(ds1)\n",
    "    for ds in datasets_ts:\n",
    "        if ds not in ds1:\n",
    "            all_tasks_test.append(ds)\n",
    "    \n",
    "    ds1 = np.random.choice(datasets_qa_s, size=2, replace=False)\n",
    "    all_tasks_train.extend(ds1)\n",
    "    for ds in datasets_qa_s:\n",
    "        if ds not in ds1:\n",
    "            all_tasks_test.append(ds)\n",
    "\n",
    "    n_train = np.random.choice([1,2])\n",
    "    ds1 = np.random.choice(datasets_qa_l, size=n_train, replace=False)\n",
    "    all_tasks_train.extend(ds1)\n",
    "    for ds in datasets_qa_l:\n",
    "        if ds not in ds1:\n",
    "            all_tasks_test.append(ds)\n",
    "\n",
    "    k = 0\n",
    "    while all_tasks_test[k] in train_exps.keys():\n",
    "        k += 1\n",
    "    train_exps[all_tasks_test[k]] = [all_tasks_train]\n",
    "    test_exps[all_tasks_test[k]] = [all_tasks_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samsum': [['cnn', 'triviaqa', 'coqa', 'truthfullqa']],\n",
       " 'sciq': [['cnn', 'xsum', 'mmlu', 'coqa', 'pubmedqa', 'truthfullqa']],\n",
       " 'cnn': [['xsum', 'samsum', 'sciq', 'triviaqa', 'pubmedqa']]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samsum': [['samsum', 'xsum', 'sciq', 'mmlu', 'pubmedqa', 'medquad']],\n",
       " 'sciq': [['samsum', 'sciq', 'triviaqa', 'medquad']],\n",
       " 'cnn': [['cnn', 'coqa', 'mmlu', 'truthfullqa', 'medquad']]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['samsum', 'sciq', 'cnn']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 1\n",
    "tasks = [ds for ds in test_exps]\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [500],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [500],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B'],\n",
    "    'cache_path': ['./workdir/gen_output_mix'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps)),\n",
    "    \"is_ood\": [True],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_mix.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text = [\"Replace me by any text you'd like.\"]\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, torch.Size([1, 12, 768]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.hidden_states), output.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 12, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cat(output.hidden_states).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = 1\n",
    "output.hidden_states[layer].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-tmd]",
   "language": "python",
   "name": "conda-env-.mlspace-tmd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "def expand_config(dict_config):\n",
    "    keys, values = zip(*dict_config.items())\n",
    "    permutations_dicts = [dict(zip(keys, v)) for v in it.product(*values)]\n",
    "    return permutations_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_str_config(config):\n",
    "    config_list = []\n",
    "    config_list.append('ignore_exceptions=False use_density_based_ue=True')\n",
    "    \n",
    "    config_list.append('batch_size={}'.format(config['batch_size']))\n",
    "\n",
    "    if \"gsm8k\" in config[\"task\"]:\n",
    "        config_list.append('subsample_train_dataset={}'.format(config['subsample_gsm8k_train_dataset']))\n",
    "    else:\n",
    "        config_list.append('subsample_train_dataset={}'.format(config['subsample_train_dataset']))\n",
    "    config_list.append('subsample_background_train_dataset={}'.format(config['subsample_background_train_dataset']))\n",
    "    config_list.append('subsample_eval_dataset={}'.format(config['subsample_eval_dataset']))\n",
    "    config_list.append('model.path={}'.format(config['model']))\n",
    "    \n",
    "    if (\"gemma\" in config['model']) or (\"mistral\" in config['model'].lower()) or (\"llama-3\" in config['model'].lower()) or (\"stablelm-2\" in config['model'].lower()):\n",
    "        config_list.append('+model.attn_implementation=eager')\n",
    "    if (\"cache_path\" in config.keys()):\n",
    "        config_list.append('cache_path={}'.format(config['cache_path']))\n",
    "    if (\"metric_thrs\" in config.keys()):\n",
    "        config_list.append('+metric_thrs={}'.format(config['metric_thrs']))\n",
    "    if (\"layers\" in config.keys()):\n",
    "        config_list.append('+layers={}'.format(config['layers'][config['model']]))\n",
    "    if (\"samples_n\" in config.keys()):\n",
    "        config_list.append('+generation_params.samples_n={}'.format(config['samples_n']))\n",
    "    return config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bash(configs, cuda_devices, tasks, generate_func, filename=''):\n",
    "    full_config = 'cd ../'\n",
    "    j = 0\n",
    "    n_devices = len(cuda_devices)\n",
    "    for i, mc_configs in enumerate(configs):\n",
    "        for conf in expand_config(mc_configs):\n",
    "            for task_name in tasks:\n",
    "                conf[\"task\"] = task_name\n",
    "                if not (\"12b\" in conf[\"model\"]):\n",
    "                    base_arg = f'CUDA_VISIBLE_DEVICES={cuda_devices[j%n_devices]} HYDRA_CONFIG=./configs/polygraph_eval_{task_name}.yaml python run_polygraph_2.py'\n",
    "                else:\n",
    "                    base_arg = f'CUDA_VISIBLE_DEVICES={cuda_devices[j%n_devices]},{cuda_devices[(j+1)%n_devices]} HYDRA_CONFIG=./configs/polygraph_eval_{task_name}.yaml python run_polygraph_2.py'\n",
    "                    j+=1\n",
    "                    \n",
    "                new_task = copy.deepcopy(base_arg)\n",
    "                args = ' '.join(generate_func[i](conf))\n",
    "                new_task += f' {args}'\n",
    "                if (j+1)%n_devices!=0: \n",
    "                    new_task += ' &'\n",
    "                else:\n",
    "                    new_task += '\\nwait'\n",
    "                full_config += '\\n' + new_task if len(full_config) else new_task\n",
    "                j+=1\n",
    "                \n",
    "    with open (f'../scripts/{filename}', 'w') as rsh:\n",
    "        rsh.write(full_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['coqa', 'sciq', 'triviaqa', 'truthfullqa', 'mmlu']\n",
    "\n",
    "layers = {\"google/gemma-7b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(27)])),\n",
    "          \"meta-llama/Meta-Llama-3-8B\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(31)])),\n",
    "          \"stabilityai/stablelm-2-12b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(39)]))}\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [1000],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['google/gemma-7b', 'meta-llama/Meta-Llama-3-8B'],# 'stabilityai/stablelm-2-12b'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_9'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p1.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['gsm8k', 'xsum', 'wmt14_deen', 'medquad', 'cnn', 'samsum', 'pubmedqa']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [1000],\n",
    "    'subsample_background_train_dataset': [500],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['google/gemma-7b', 'meta-llama/Meta-Llama-3-8B'],# 'stabilityai/stablelm-2-12b'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_9'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0,1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p2.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['sciq', 'coqa', 'triviaqa', 'truthfullqa', 'mmlu', 'samsum', 'pubmedqa', 'wmt14_deen', 'cnn']\n",
    "\n",
    "layers = {\"google/gemma-7b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(27)])),\n",
    "          \"meta-llama/Meta-Llama-3-8B\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(31)])),\n",
    "          \"stabilityai/stablelm-2-12b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(39)]))}\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['google/gemma-7b', 'meta-llama/Meta-Llama-3-8B'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_3'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p1_1.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['gsm8k', 'xsum', 'medquad']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['google/gemma-7b', 'meta-llama/Meta-Llama-3-8B'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_3'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1,2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p2_1.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['sciq', 'coqa', 'triviaqa', 'truthfullqa', 'mmlu', 'samsum', 'pubmedqa', 'wmt14_deen', 'gsm8k', 'xsum', 'medquad', 'cnn']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['stabilityai/stablelm-2-12b'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_3'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1,2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p3_1.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['pubmedqa', 'wmt14_deen', 'cnn']\n",
    "\n",
    "layers = {\"google/gemma-7b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(27)])),\n",
    "          \"meta-llama/Meta-Llama-3-8B\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(31)])),\n",
    "          \"stabilityai/stablelm-2-12b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(39)]))}\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3-8B'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_3'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p1_2.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['gsm8k', 'xsum', 'medquad', 'cnn']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    \"subsample_gsm8k_train_dataset\": [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['stabilityai/stablelm-2-12b'],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_3'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1,2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_p3_2.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-tmd]",
   "language": "python",
   "name": "conda-env-.mlspace-tmd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "def expand_config(dict_config):\n",
    "    keys, values = zip(*dict_config.items())\n",
    "    permutations_dicts = [dict(zip(keys, v)) for v in it.product(*values)]\n",
    "    return permutations_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bash(configs, cuda_devices, tasks, generate_func, filename='', scripts=\"run_polygraph_2.py\"):\n",
    "    full_config = 'cd ../'\n",
    "    j = 0\n",
    "    n_devices = len(cuda_devices)\n",
    "    for i, mc_configs in enumerate(configs):\n",
    "        for conf in expand_config(mc_configs):\n",
    "            for task_name in tasks:\n",
    "                conf[\"task\"] = task_name\n",
    "                if not (\"12b\" in conf[\"model\"]):\n",
    "                    base_arg = f'CUDA_VISIBLE_DEVICES={cuda_devices[j%n_devices]} HYDRA_CONFIG=./configs/polygraph_eval_{task_name}.yaml python {scripts}'\n",
    "                else:\n",
    "                    base_arg = f'CUDA_VISIBLE_DEVICES={cuda_devices[j%n_devices]},{cuda_devices[(j+1)%n_devices]} HYDRA_CONFIG=./configs/polygraph_eval_{task_name}.yaml python {scripts}'\n",
    "                    j+=1\n",
    "                    \n",
    "                new_task = copy.deepcopy(base_arg)\n",
    "                args = ' '.join(generate_func[i](conf))\n",
    "                new_task += f' {args}'\n",
    "                if (j+1)%n_devices!=0: \n",
    "                    new_task += ' &'\n",
    "                else:\n",
    "                    new_task += '\\nwait'\n",
    "                full_config += '\\n' + new_task if len(full_config) else new_task\n",
    "                j+=1\n",
    "                \n",
    "    with open (f'../scripts/{filename}', 'w') as rsh:\n",
    "        rsh.write(full_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_str_config(config):\n",
    "    config_list = []\n",
    "    config_list.append('ignore_exceptions=False use_density_based_ue=True')\n",
    "    \n",
    "    config_list.append('batch_size={}'.format(config['batch_size']))\n",
    "\n",
    "    if (\"gsm8k\" in config[\"task\"]) or (\"medquad\" in config[\"task\"]) or (\"samsum\" in config[\"task\"]):\n",
    "        config_list.append('subsample_train_dataset={}'.format(config['subsample_gsm8k_train_dataset']))\n",
    "    else:\n",
    "        config_list.append('subsample_train_dataset={}'.format(config['subsample_train_dataset']))\n",
    "    if config.get(\"ablation\", False):\n",
    "        if (\"gsm8k\" in config[\"task\"]) or (\"medquad\" in config[\"task\"]) or (\"samsum\" in config[\"task\"]):\n",
    "            config_list.append('subsample_background_train_dataset={}'.format(config['subsample_gsm8k_train_dataset']))\n",
    "        else:\n",
    "            config_list.append('subsample_background_train_dataset={}'.format(config['subsample_train_dataset']))\n",
    "    else:\n",
    "        config_list.append('subsample_background_train_dataset={}'.format(config['subsample_background_train_dataset']))\n",
    "    config_list.append('subsample_eval_dataset={}'.format(config['subsample_eval_dataset']))\n",
    "    config_list.append('model.path={}'.format(config['model']))\n",
    "    \n",
    "    if (\"gemma\" in config['model']) or (\"mistral\" in config['model'].lower()) or (\"llama-3\" in config['model'].lower()) or (\"stablelm-2\" in config['model'].lower()):\n",
    "        config_list.append('+model.attn_implementation=eager')\n",
    "    if (\"cache_path\" in config.keys()) and config.get(\"ablation\", False):\n",
    "        config_list.append('cache_path={}_{}'.format(config['cache_path'], config['subsample_train_dataset']))\n",
    "    elif (\"cache_path\" in config.keys()):\n",
    "        config_list.append('cache_path={}'.format(config['cache_path']))\n",
    "    if (\"metric_thrs\" in config.keys()):\n",
    "        config_list.append('+metric_thrs={}'.format(config['metric_thrs']))\n",
    "    if (\"layers\" in config.keys()):\n",
    "        config_list.append('+layers={}'.format(config['layers'][config['model']]))\n",
    "    if (\"samples_n\" in config.keys()):\n",
    "        config_list.append('+generation_params.samples_n={}'.format(config['samples_n']))\n",
    "    if (\"baselines\" in config.keys()):\n",
    "        if config['baselines'] == \"all\":\n",
    "            config_list.append('+run_baselines=True')\n",
    "            config_list.append('+md_device=cuda')\n",
    "            config_list.append('+run_proposed_methods=True')\n",
    "            config_list.append('+clean_md_device=cuda')\n",
    "        elif config['baselines']:\n",
    "            config_list.append('+run_baselines=True')\n",
    "            config_list.append('+md_device=cuda')\n",
    "        else:\n",
    "            config_list.append('+run_proposed_methods=True')\n",
    "            config_list.append('+run_layerwise_methods=True')\n",
    "            config_list.append('+clean_md_device=cuda')\n",
    "            config_list.append('+md_device=cuda')\n",
    "            config_list.append('+run_eigenscore=False')\n",
    "                \n",
    "    if (\"use_truefalse_dataset\" in config.keys()):\n",
    "        config_list.append('+use_truefalse_dataset={}'.format(config['use_truefalse_dataset']))\n",
    "        if (config[\"use_truefalse_dataset\"]):\n",
    "            config_list.append('train_dataset=../data/publicDataset/truefalsedata.csv +train_text_column=statement +train_label_column=label')\n",
    "    return config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = {\"google/gemma-2-9b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(41)])),\n",
    "          \"meta-llama/Meta-Llama-3.1-8B\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(31)])),\n",
    "          \"stabilityai/stablelm-2-12b\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(39)])),\n",
    "          \"Qwen/Qwen2.5-7B\": \"\\\"[{},-1]\\\"\".format(\",\".join([str(x) for x in range(27)])),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['sciq', 'coqa', 'triviaqa', 'mmlu', 'truthfullqa', 'samsum']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"google/gemma-2-9b\"],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'baselines': [\"all\"],#[False, True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_final_1.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['gsm8k', 'medquad', 'xsum']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"google/gemma-2-9b\"],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'baselines': [\"all\"],#[False, True],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_final_2.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['pubmedqa', 'cnn', \"wmt19_deen\"]\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"google/gemma-2-9b\"],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'baselines': [\"all\"],#False, True],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_final_3.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train size ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['sciq']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"google/gemma-2-9b\"],\n",
    "    'subsample_train_dataset': [100, 200, 500, 1000, 2000],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_ablation'],\n",
    "    'baselines': [False],\n",
    "    'ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_1.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['truthfullqa']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"google/gemma-2-9b\"],\n",
    "    'subsample_train_dataset': [100, 200, 500],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_ablation'],\n",
    "    'baselines': [False],\n",
    "    'ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_1_1.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['mmlu', 'cnn']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"google/gemma-2-9b\"],\n",
    "    'subsample_train_dataset': [100, 200, 500, 1000, 2000],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'baselines': [False],\n",
    "    'ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_2.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['medquad']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"google/gemma-2-9b\"],\n",
    "    'subsample_gsm8k_train_dataset': [100, 200, 500, 1000, 2000],\n",
    "    'subsample_train_dataset': [100],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'baselines': [False],\n",
    "    'ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_3.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['gsm8k']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\", \"google/gemma-2-9b\"],\n",
    "    'subsample_gsm8k_train_dataset': [100, 200, 500, 1000, 2000],\n",
    "    'subsample_train_dataset': [100],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'baselines': [False],\n",
    "    'ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_4.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['samsum']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\"],\n",
    "    'subsample_gsm8k_train_dataset': [100, 200, 500, 1000],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_layers_internal_final'],\n",
    "    'baselines': [False],\n",
    "    'ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_5.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pca & thr ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_str_config(config):\n",
    "    config_list = []\n",
    "    config_list.append('ignore_exceptions=False use_density_based_ue=True')\n",
    "    \n",
    "    config_list.append('batch_size={}'.format(config['batch_size']))\n",
    "\n",
    "    if (\"gsm8k\" in config[\"task\"]) or (\"medquad\" in config[\"task\"]) or (\"samsum\" in config[\"task\"]):\n",
    "        config_list.append('subsample_train_dataset={}'.format(config['subsample_gsm8k_train_dataset']))\n",
    "    else:\n",
    "        config_list.append('subsample_train_dataset={}'.format(config['subsample_train_dataset']))\n",
    "    if config.get(\"ablation\", False):\n",
    "        if (\"gsm8k\" in config[\"task\"]) or (\"medquad\" in config[\"task\"]) or (\"samsum\" in config[\"task\"]):\n",
    "            config_list.append('subsample_background_train_dataset={}'.format(config['subsample_gsm8k_train_dataset']))\n",
    "        else:\n",
    "            config_list.append('subsample_background_train_dataset={}'.format(config['subsample_train_dataset']))\n",
    "    else:\n",
    "        config_list.append('subsample_background_train_dataset={}'.format(config['subsample_background_train_dataset']))\n",
    "    config_list.append('subsample_eval_dataset={}'.format(config['subsample_eval_dataset']))\n",
    "    config_list.append('model.path={}'.format(config['model']))\n",
    "    \n",
    "    if (\"gemma\" in config['model']) or (\"mistral\" in config['model'].lower()) or (\"llama-3\" in config['model'].lower()) or (\"stablelm-2\" in config['model'].lower()):\n",
    "        config_list.append('+model.attn_implementation=eager')\n",
    "    if (\"cache_path\" in config.keys()) and config.get(\"ablation\", False):\n",
    "        config_list.append('cache_path={}_{}'.format(config['cache_path'], config['subsample_train_dataset']))\n",
    "    elif (\"cache_path\" in config.keys()):\n",
    "        config_list.append('cache_path={}'.format(config['cache_path']))\n",
    "    if (\"metric_thrs\" in config.keys()):\n",
    "        config_list.append('+metric_thrs={}'.format(config['metric_thrs']))\n",
    "    if (\"n_components\" in config.keys()):\n",
    "        config_list.append('+n_components={}'.format(config['n_components']))\n",
    "    if (\"layers\" in config.keys()):\n",
    "        config_list.append('+layers={}'.format(config['layers'][config['model']]))\n",
    "    if (\"samples_n\" in config.keys()):\n",
    "        config_list.append('+generation_params.samples_n={}'.format(config['samples_n']))\n",
    "    if (\"baselines\" in config.keys()):\n",
    "        if config['baselines'] == \"all\":\n",
    "            config_list.append('+run_baselines=True')\n",
    "            config_list.append('+md_device=cuda')\n",
    "            config_list.append('+run_proposed_methods=True')\n",
    "            config_list.append('+clean_md_device=cuda')\n",
    "        elif config['baselines']:\n",
    "            config_list.append('+run_baselines=True')\n",
    "            config_list.append('+md_device=cuda')\n",
    "        else:\n",
    "            config_list.append('+run_proposed_methods=True')\n",
    "            config_list.append('+run_layerwise_methods=True')\n",
    "            config_list.append('+clean_md_device=cuda')\n",
    "            config_list.append('+md_device=cuda')\n",
    "            config_list.append('+run_eigenscore=False')\n",
    "            \n",
    "    if (\"run_ablation\" in config.keys()):\n",
    "        config_list.append('+run_baselines=False')\n",
    "        config_list.append('+run_proposed_methods=False')\n",
    "        config_list.append('+run_layerwise_methods=False')\n",
    "        config_list.append('+clean_md_device=cuda')\n",
    "        config_list.append('+md_device=cuda')\n",
    "        config_list.append('+run_eigenscore=False')\n",
    "        config_list.append('+run_ablation={}'.format(config['run_ablation']))\n",
    "        \n",
    "    if (\"use_truefalse_dataset\" in config.keys()):\n",
    "        config_list.append('+use_truefalse_dataset={}'.format(config['use_truefalse_dataset']))\n",
    "        if (config[\"use_truefalse_dataset\"]):\n",
    "            config_list.append('train_dataset=../data/publicDataset/truefalsedata.csv +train_text_column=statement +train_label_column=label')\n",
    "    return config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tasks = ['sciq', 'coqa', 'triviaqa', 'mmlu', 'truthfullqa']#, 'samsum']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\"],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    'metric_thrs': [\"\\\"[0.1,0.3,0.5,0.8]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_ablation_thr'],\n",
    "    'run_ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_thr_1.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['sciq', 'coqa', 'triviaqa', 'mmlu', 'truthfullqa']#, 'samsum']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\"],\n",
    "    'subsample_train_dataset': [5000],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'n_components': [\"\\\"[2,5,10,20,30]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_ablation_pca'],\n",
    "    'run_ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_pca_1.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['gsm8k', 'medquad', 'xsum', 'pubmedqa', 'cnn']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\"],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'metric_thrs': [\"\\\"[0.1,0.3,0.5,0.8]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_ablation_thr'],\n",
    "    'run_ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_thr_2.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['gsm8k', 'medquad', 'xsum', 'pubmedqa', 'cnn']\n",
    "\n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'subsample_gsm8k_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [2000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': [\"meta-llama/Meta-Llama-3.1-8B\"],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'n_components': [\"\\\"[2,5,10,20,30]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    'cache_path': ['./workdir/output_ablation_pca'],\n",
    "    'run_ablation': [True],\n",
    "    'samples_n': [5],\n",
    "}\n",
    "    \n",
    "cuda_devices = [2]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], 'run_tmd_exps_abl_pca_2.sh', scripts=\"run_polygraph.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def generate_train_str_config(config, task_name):\n",
    "    config_list = []\n",
    "    config_list.append('ignore_exceptions=False use_density_based_ue=True')\n",
    "    \n",
    "    config_list.append('batch_size={}'.format(config['batch_size']))\n",
    "    config_list.append('train_test_split=False')\n",
    "    config_list.append('subsample_train_dataset={}'.format(config['subsample_train_dataset']))\n",
    "    config_list.append('subsample_background_train_dataset={}'.format(config['subsample_background_train_dataset']))\n",
    "    config_list.append('subsample_eval_dataset={}'.format(config['subsample_eval_dataset']))\n",
    "    config_list.append('model.path={}'.format(config['model']))\n",
    "    if (\"gemma\" in config['model']) or (\"mistral\" in config['model'].lower()) or (\"llama-3\" in config['model'].lower()) or (\"stablelm-2\" in config['model'].lower()):\n",
    "        config_list.append('+model.attn_implementation=eager')\n",
    "    if (\"cache_path\" in config.keys()) and not config.get(\"upd_path\", False):\n",
    "        config_list.append('cache_path={}'.format(config['cache_path']))\n",
    "    if (\"samples_n\" in config.keys()):\n",
    "        config_list.append('+generation_params.samples_n={}'.format(config['samples_n']))\n",
    "    if (\"metric_thrs\" in config.keys()):\n",
    "        config_list.append('+metric_thrs={}'.format(config['metric_thrs']))\n",
    "    if (\"layers\" in config.keys()):\n",
    "        config_list.append('+layers={}'.format(config['layers'][config['model']]))\n",
    "    if config.get(\"generalization\", False):\n",
    "        try:\n",
    "            ood_cfg = gen_tasks[task_name][config[\"exp_idx\"]]\n",
    "        except:\n",
    "            return \"\"\n",
    "        for i, ds in enumerate(ood_cfg):\n",
    "            if (\"cache_path\" in config.keys()) and config.get(\"upd_path\", False):\n",
    "                config_list.append('cache_path={}_on_{}'.format(config['cache_path'], ds))\n",
    "            with open(f\"../configs/polygraph_eval_{ds}.yaml\") as stream:\n",
    "                gen_config = yaml.safe_load(stream)\n",
    "            config_list.append('+max_new_tokens_{}={}'.format(i+1, gen_config['max_new_tokens']))\n",
    "            config_list.append('+train_dataset_{}=\\\"{}\\\"'.format(i+1, gen_config['dataset']))\n",
    "            config_list.append('+train_text_column_{}={}'.format(i+1, gen_config['text_column']))\n",
    "            config_list.append('+train_label_column_{}={}'.format(i+1, gen_config['label_column']))\n",
    "            config_list.append('+train_prompt_{}=\\\"{}\\\"'.format(i+1, gen_config['prompt']))\n",
    "            \n",
    "            config_list[-1] = config_list[-1].replace(\"\\n\", \"\\\\n\")\n",
    "            config_list[-1] = config_list[-1].replace(\"$\", \"\\\\$\")\n",
    "            config_list[-1] = config_list[-1].replace(\"'s\", \" is\")\n",
    "            config_list[-1] = config_list[-1].replace(\"(\", \"\\\\(\")\n",
    "            config_list[-1] = config_list[-1].replace(\")\", \"\\\\)\")\n",
    "            config_list[-1] = config_list[-1].replace(\"}\", \"\\\\}\")\n",
    "            config_list[-1] = config_list[-1].replace(\"{\", \"\\\\{\")\n",
    "            config_list[-1] = config_list[-1].replace(\"]\", \"\\\\]\")\n",
    "            config_list[-1] = config_list[-1].replace(\"[\", \"\\\\[\")\n",
    "            config_list[-1] = config_list[-1].replace(\",\", \"\\\\,\")\n",
    "            config_list[-1] = config_list[-1].replace(\"=\", \"\\\\=\")\n",
    "            # config_list[-1] = config_list[-1].replace(\"+\", \"\\\\+\")\n",
    "            config_list.append('+train_split_{}={}'.format(i+1, gen_config['train_split']))\n",
    "\n",
    "            if \"description\" in gen_config.keys():\n",
    "                config_list.append(\"+train_description_{}=\\\"{}\\\"\".format(i+1, gen_config['description']))\n",
    "                config_list[-1] = config_list[-1].replace(\"\\n\", \"\\\\n\")\n",
    "                config_list[-1] = config_list[-1].replace(\"'s\", \" is\")\n",
    "                config_list[-1] = config_list[-1].replace(\"(\", \"\\\\(\")\n",
    "                config_list[-1] = config_list[-1].replace(\")\", \"\\\\)\")\n",
    "                config_list[-1] = config_list[-1].replace(\"}\", \"\\\\}\")\n",
    "                config_list[-1] = config_list[-1].replace(\"{\", \"\\\\{\")\n",
    "                config_list[-1] = config_list[-1].replace(\",\", \"\\\\,\")\n",
    "                config_list[-1] = config_list[-1].replace(\"$\", \"\\\\$\")\n",
    "                config_list[-1] = config_list[-1].replace(\"=\", \"\\\\=\")\n",
    "                config_list[-1] = config_list[-1].replace(\"]\", \"\\\\]\")\n",
    "                config_list[-1] = config_list[-1].replace(\"[\", \"\\\\[\")\n",
    "                # config_list[-1] = config_list[-1].replace(\"+\", \"\\\\+\")\n",
    "                \n",
    "            if \"few_shot_split\" in gen_config.keys():\n",
    "                config_list.append('+few_shot_split_{}={}'.format(i+1, gen_config['few_shot_split']))\n",
    "            if \"n_shot\" in gen_config.keys():\n",
    "                config_list.append('+train_n_shot_{}={}'.format(i+1, gen_config['n_shot']))\n",
    "    if (\"baselines\" in config.keys()):\n",
    "        if config['baselines'] == \"all\":\n",
    "            config_list.append('+run_baselines=False')\n",
    "            config_list.append('+run_eigenscore=False')\n",
    "            config_list.append('+md_device=cuda')\n",
    "            config_list.append('+run_proposed_methods=True')\n",
    "            config_list.append('+run_layerwise_methods=True')\n",
    "            config_list.append('+clean_md_device=cuda')\n",
    "        elif config['baselines']:\n",
    "            config_list.append('+run_baselines=False')\n",
    "            config_list.append('+run_eigenscore=False')\n",
    "            config_list.append('+run_layerwise_methods=True')\n",
    "            config_list.append('+md_device=cuda')\n",
    "        else:\n",
    "            config_list.append('+run_proposed_methods=True')\n",
    "            config_list.append('+clean_md_device=cuda')\n",
    "    if \"is_ood\" in config.keys():\n",
    "        config_list.append('+is_ood={}'.format(config['is_ood']))\n",
    "        \n",
    "    return config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bash(configs, cuda_devices, tasks, generate_func, script_name=\"polygraph_eval\", filename='', n_gpus=1):\n",
    "    full_config = 'cd ../'\n",
    "    j = 0\n",
    "    print(tasks)\n",
    "    n_devices = len(cuda_devices)\n",
    "    for i, mc_configs in enumerate(configs):\n",
    "        for conf in expand_config(mc_configs):\n",
    "            for task_name in tasks:\n",
    "                \n",
    "                if (n_gpus == 1) or ((task_name not in [\"gsm8k\", \"xsum\", \"medquad\"]) and ((\"7b\" in conf[\"model\"]) or (\"8b\" not in conf[\"model\"]))):\n",
    "                    base_arg = f'CUDA_VISIBLE_DEVICES={cuda_devices[j%n_devices]} HYDRA_CONFIG=./configs/polygraph_eval_{task_name}.yaml python run_polygraph.py'\n",
    "                else:\n",
    "                    base_arg = f'CUDA_VISIBLE_DEVICES={cuda_devices[j%n_devices]},{cuda_devices[(j+1)%n_devices]} HYDRA_CONFIG=./configs/polygraph_eval_{task_name}.yaml python run_polygraph.py'\n",
    "                    j+=1\n",
    "                    \n",
    "                new_task = copy.deepcopy(base_arg)\n",
    "                args = ' '.join(generate_func[i](conf, task_name))\n",
    "                if not len(args.strip()):\n",
    "                    continue\n",
    "                new_task += f' {args}'\n",
    "                if (j+1)%n_devices!=0: \n",
    "                    new_task += ' &'\n",
    "                else:\n",
    "                    new_task += '\\nwait'\n",
    "                full_config += '\\n' + new_task if len(full_config) else new_task\n",
    "                j+=1\n",
    "                \n",
    "    with open (f'../scripts/{filename}', 'w') as rsh:\n",
    "        rsh.write(full_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_ts = ['samsum', 'xsum', 'cnn']\n",
    "datasets_tr = ['wmt14_fren', \"wmt19_deen\"]\n",
    "datasets_qa_s = ['sciq', 'coqa', 'triviaqa', 'mmlu']\n",
    "# datasets_qa_l = ['truthfullqa', 'pubmedqa', 'medquad']\n",
    "datasets_qa_l = ['truthfullqa', 'pubmedqa']\n",
    "all_tasks = [datasets_ts, datasets_qa_s, datasets_qa_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 1\n",
    "tasks = ['truthfullqa', 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    all_tasks_i = [x for x in np.concatenate(all_tasks) if x != task] \n",
    "    for i, ds in enumerate(all_tasks_i):\n",
    "        ds_exps.append(ds)\n",
    "    gen_tasks[task].append(ds_exps)\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [1000],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B'],\n",
    "    'cache_path': ['./workdir/gen_output_loo_new'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps)),\n",
    "    \"is_ood\": [True],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_v2_all.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 1\n",
    "tasks = ['mmlu', 'truthfullqa', 'samsum', 'sciq']#, 'cnn', 'samsum']#, 'medquad', 'xsum', 'pubmedqa', 'wmt14_fren', 'cnn', \"wmt19_deen\", 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    all_tasks_i = [x for x in np.concatenate(all_tasks) if x != task] \n",
    "    for i, ds in enumerate(all_tasks_i):\n",
    "        ds_exps.append(ds)\n",
    "    gen_tasks[task].append(ds_exps)\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [400],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B'],\n",
    "    'cache_path': ['./workdir/gen_output_loo_new'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps)),\n",
    "    \"is_ood\": [True],\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_v2_1.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 1\n",
    "tasks = ['mmlu', 'truthfullqa', 'samsum', 'sciq']#, 'cnn', 'samsum']#, 'medquad', 'xsum', 'pubmedqa', 'wmt14_fren', 'cnn', \"wmt19_deen\", 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    for i, ds_tasks in enumerate(all_tasks):\n",
    "        if task in ds_tasks:\n",
    "            for ds in ds_tasks:\n",
    "                if ds != task:\n",
    "                    ds_exps.append(ds)\n",
    "    gen_tasks[task].append(ds_exps)\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [400],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B'],\n",
    "    'cache_path': ['./workdir/gen_output_loo_new'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps)),\n",
    "    \"is_ood\": [True],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_v2_2.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 1\n",
    "tasks = ['mmlu', 'truthfullqa', 'samsum', 'sciq']#, 'cnn', 'samsum']#, 'medquad', 'xsum', 'pubmedqa', 'wmt14_fren', 'cnn', \"wmt19_deen\", 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    for i, ds_tasks in enumerate(all_tasks):\n",
    "        if task in ds_tasks:\n",
    "            for ds in ds_tasks:\n",
    "                if ds != task:\n",
    "                    ds_exps.append(ds)\n",
    "    gen_tasks[task].append(ds_exps)\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [1000],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B'],\n",
    "    'cache_path': ['./workdir/gen_output_loo_new'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps)),\n",
    "    \"is_ood\": [True],\n",
    "}\n",
    "    \n",
    "cuda_devices = [1]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_v2_3.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "n_exps = 3\n",
    "tasks = ['mmlu', 'truthfullqa', 'samsum', 'sciq']#, 'cnn', 'samsum']#, 'medquad', 'xsum', 'pubmedqa', 'wmt14_fren', 'cnn', \"wmt19_deen\", 'samsum']\n",
    "gen_tasks = {}\n",
    "for k, task in enumerate(tasks):\n",
    "    gen_tasks[task] = []\n",
    "    ds_exps = []\n",
    "    for i, ds_tasks in enumerate(all_tasks):\n",
    "        if task in ds_tasks:\n",
    "            for ds in ds_tasks:\n",
    "                if ds != task:\n",
    "                    # ds_exps.append(ds)\n",
    "                    gen_tasks[task].append([ds])\n",
    "print(gen_tasks)\n",
    "    \n",
    "train_configs = {\n",
    "    'batch_size': [1],\n",
    "    'baselines': [\"all\"],\n",
    "    'subsample_train_dataset': [2000],\n",
    "    'subsample_background_train_dataset': [1000],\n",
    "    'subsample_eval_dataset': [2000],\n",
    "    'model': ['meta-llama/Meta-Llama-3.1-8B'],\n",
    "    'cache_path': ['./workdir/gen_output_loo_new'],\n",
    "    'samples_n': [5],\n",
    "    'generalization': [True], \n",
    "    'metric_thrs': [\"\\\"[0.3]\\\"\"],\n",
    "    'layers': [layers],\n",
    "    \"exp_idx\": list(range(n_exps)),\n",
    "    \"is_ood\": [True],\n",
    "    \"upd_path\": [True]\n",
    "}\n",
    "    \n",
    "cuda_devices = [0]\n",
    "\n",
    "generate_bash([train_configs], cuda_devices, tasks, [generate_train_str_config], filename='generalization/run_tmd_exps_v2_4.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-tmd]",
   "language": "python",
   "name": "conda-env-.mlspace-tmd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

cd ../
# CUDA_VISIBLE_DEVICES=0 HYDRA_CONFIG=./configs/polygraph_eval_mmlu.yaml python run_polygraph.py ignore_exceptions=False use_density_based_ue=True batch_size=1 subsample_train_dataset=2000 subsample_background_train_dataset=1000 subsample_eval_dataset=2000 model.path=meta-llama/Meta-Llama-3.1-8B +model.attn_implementation=eager +generation_params.samples_n=5 +metric_thrs="[0.3]" +layers="[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,-1]" cache_path=./workdir/gen_output_loo_new_on_sciq +max_new_tokens_1=20 +train_dataset_1="sciq" +train_text_column_1=question +train_label_column_1=correct_answer +train_prompt_1\="\n\nQuestion: \{question\}\nAnswer:" +train_split_1=train +train_description_1\="The following are context and question about them. Each context is followed by a question and answer to a given question.\n\nContext: \{context\}" +run_baselines=False +run_eigenscore=False +md_device=cuda +run_proposed_methods=True +run_layerwise_methods=True +clean_md_device=cuda +is_ood=True
# wait
# CUDA_VISIBLE_DEVICES=0 HYDRA_CONFIG=./configs/polygraph_eval_truthfullqa.yaml python run_polygraph.py ignore_exceptions=False use_density_based_ue=True batch_size=1 subsample_train_dataset=2000 subsample_background_train_dataset=1000 subsample_eval_dataset=2000 model.path=meta-llama/Meta-Llama-3.1-8B +model.attn_implementation=eager +generation_params.samples_n=5 +metric_thrs="[0.3]" +layers="[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,-1]" cache_path=./workdir/gen_output_loo_new_on_pubmedqa +max_new_tokens_1=128 +train_dataset_1="bigbio/pubmed_qa" +train_text_column_1=QUESTION +train_label_column_1=LONG_ANSWER +train_prompt_1\="The following are abstract and question about them. Each abstract is followed by a question and answer to a given question. Abstract: \{context\}\nQuestion: \{question\}\nAnswer:" +train_split_1=train +train_n_shot_1=0 +run_baselines=False +run_eigenscore=False +md_device=cuda +run_proposed_methods=True +run_layerwise_methods=True +clean_md_device=cuda +is_ood=True
# wait
# CUDA_VISIBLE_DEVICES=0 HYDRA_CONFIG=./configs/polygraph_eval_samsum.yaml python run_polygraph.py ignore_exceptions=False use_density_based_ue=True batch_size=1 subsample_train_dataset=2000 subsample_background_train_dataset=1000 subsample_eval_dataset=2000 model.path=meta-llama/Meta-Llama-3.1-8B +model.attn_implementation=eager +generation_params.samples_n=5 +metric_thrs="[0.3]" +layers="[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,-1]" cache_path=./workdir/gen_output_loo_new_on_xsum +max_new_tokens_1=56 +train_dataset_1="xsum" +train_text_column_1=document +train_label_column_1=summary +train_prompt_1\="Here is the text and it is short one-sentence summary.\n\nText:\n\{text\}\n\nSummary \(one sentence\):\n" +train_split_1=train +run_baselines=False +run_eigenscore=False +md_device=cuda +run_proposed_methods=True +run_layerwise_methods=True +clean_md_device=cuda +is_ood=True
# wait
# CUDA_VISIBLE_DEVICES=0 HYDRA_CONFIG=./configs/polygraph_eval_sciq.yaml python run_polygraph.py ignore_exceptions=False use_density_based_ue=True batch_size=1 subsample_train_dataset=2000 subsample_background_train_dataset=1000 subsample_eval_dataset=2000 model.path=meta-llama/Meta-Llama-3.1-8B +model.attn_implementation=eager +generation_params.samples_n=5 +metric_thrs="[0.3]" +layers="[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,-1]" cache_path=./workdir/gen_output_loo_new_on_coqa +max_new_tokens_1=20 +train_dataset_1="coqa" +train_text_column_1=questions +train_label_column_1=answers +train_prompt_1\="\n\nQuestion: \{question\}\nAnswer:\{answer\}" +train_split_1=train +train_description_1\="The following are stories and questions about them. Each story is followed by a question and answer to a given question.\n\nStory: \{story\}" +run_baselines=False +run_eigenscore=False +md_device=cuda +run_proposed_methods=True +run_layerwise_methods=True +clean_md_device=cuda +is_ood=True
# wait
# CUDA_VISIBLE_DEVICES=0 HYDRA_CONFIG=./configs/polygraph_eval_mmlu.yaml python run_polygraph.py ignore_exceptions=False use_density_based_ue=True batch_size=1 subsample_train_dataset=2000 subsample_background_train_dataset=1000 subsample_eval_dataset=2000 model.path=meta-llama/Meta-Llama-3.1-8B +model.attn_implementation=eager +generation_params.samples_n=5 +metric_thrs="[0.3]" +layers="[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,-1]" cache_path=./workdir/gen_output_loo_new_on_coqa +max_new_tokens_1=20 +train_dataset_1="coqa" +train_text_column_1=questions +train_label_column_1=answers +train_prompt_1\="\n\nQuestion: \{question\}\nAnswer:\{answer\}" +train_split_1=train +train_description_1\="The following are stories and questions about them. Each story is followed by a question and answer to a given question.\n\nStory: \{story\}" +run_baselines=False +run_eigenscore=False +md_device=cuda +run_proposed_methods=True +run_layerwise_methods=True +clean_md_device=cuda +is_ood=True
# wait
# CUDA_VISIBLE_DEVICES=0 HYDRA_CONFIG=./configs/polygraph_eval_truthfullqa.yaml python run_polygraph.py ignore_exceptions=False use_density_based_ue=True batch_size=1 subsample_train_dataset=2000 subsample_background_train_dataset=1000 subsample_eval_dataset=2000 model.path=meta-llama/Meta-Llama-3.1-8B +model.attn_implementation=eager +generation_params.samples_n=5 +metric_thrs="[0.3]" +layers="[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,-1]" cache_path=./workdir/gen_output_loo_new_on_medquad +max_new_tokens_1=128 +train_dataset_1="keivalya/MedQuad-MedicalQnADataset" +train_text_column_1=Question +train_label_column_1=Answer +train_prompt_1\="Question: \{question\}\nAnswer: \{answer\}" +train_split_1=train +few_shot_split_1=train +train_n_shot_1=5 +run_baselines=False +run_eigenscore=False +md_device=cuda +run_proposed_methods=True +run_layerwise_methods=True +clean_md_device=cuda +is_ood=True
# wait
CUDA_VISIBLE_DEVICES=0 HYDRA_CONFIG=./configs/polygraph_eval_samsum.yaml python run_polygraph.py ignore_exceptions=False use_density_based_ue=True batch_size=1 subsample_train_dataset=2000 subsample_background_train_dataset=1000 subsample_eval_dataset=2000 model.path=meta-llama/Meta-Llama-3.1-8B +model.attn_implementation=eager +generation_params.samples_n=5 +metric_thrs="[0.3]" +layers="[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,-1]" cache_path=./workdir/gen_output_loo_new_on_cnn +max_new_tokens_1=128 +train_dataset_1="['cnn_dailymail', '3.0.0']" +train_text_column_1=article +train_label_column_1=highlights +train_prompt_1\="Here is the text and it is short summary.\n\nText:\n\{text\}\n\nSummary \(one sentence\):\n" +train_split_1=train +run_baselines=False +run_eigenscore=False +md_device=cuda +run_proposed_methods=True +run_layerwise_methods=True +clean_md_device=cuda +is_ood=True
wait
CUDA_VISIBLE_DEVICES=0 HYDRA_CONFIG=./configs/polygraph_eval_sciq.yaml python run_polygraph.py ignore_exceptions=False use_density_based_ue=True batch_size=1 subsample_train_dataset=2000 subsample_background_train_dataset=1000 subsample_eval_dataset=2000 model.path=meta-llama/Meta-Llama-3.1-8B +model.attn_implementation=eager +generation_params.samples_n=5 +metric_thrs="[0.3]" +layers="[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,-1]" cache_path=./workdir/gen_output_loo_new_on_triviaqa +max_new_tokens_1=20 +train_dataset_1="['trivia_qa', 'rc.nocontext']" +train_text_column_1=question +train_label_column_1=answer +train_prompt_1\="Question: \{question\}\nAnswer:\{answer\}" +train_split_1=train +few_shot_split_1=train +train_n_shot_1=5 +run_baselines=False +run_eigenscore=False +md_device=cuda +run_proposed_methods=True +run_layerwise_methods=True +clean_md_device=cuda +is_ood=True
wait
CUDA_VISIBLE_DEVICES=0 HYDRA_CONFIG=./configs/polygraph_eval_mmlu.yaml python run_polygraph.py ignore_exceptions=False use_density_based_ue=True batch_size=1 subsample_train_dataset=2000 subsample_background_train_dataset=1000 subsample_eval_dataset=2000 model.path=meta-llama/Meta-Llama-3.1-8B +model.attn_implementation=eager +generation_params.samples_n=5 +metric_thrs="[0.3]" +layers="[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,-1]" cache_path=./workdir/gen_output_loo_new_on_triviaqa +max_new_tokens_1=20 +train_dataset_1="['trivia_qa', 'rc.nocontext']" +train_text_column_1=question +train_label_column_1=answer +train_prompt_1\="Question: \{question\}\nAnswer:\{answer\}" +train_split_1=train +few_shot_split_1=train +train_n_shot_1=5 +run_baselines=False +run_eigenscore=False +md_device=cuda +run_proposed_methods=True +run_layerwise_methods=True +clean_md_device=cuda +is_ood=True
wait
CUDA_VISIBLE_DEVICES=0 HYDRA_CONFIG=./configs/polygraph_eval_sciq.yaml python run_polygraph.py ignore_exceptions=False use_density_based_ue=True batch_size=1 subsample_train_dataset=2000 subsample_background_train_dataset=1000 subsample_eval_dataset=2000 model.path=meta-llama/Meta-Llama-3.1-8B +model.attn_implementation=eager +generation_params.samples_n=5 +metric_thrs="[0.3]" +layers="[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,-1]" cache_path=./workdir/gen_output_loo_new_on_mmlu +max_new_tokens_1=3 +train_dataset_1="['cais/mmlu', 'all']" +train_text_column_1=question +train_label_column_1=answer +train_prompt_1\="\nQ:\{question\}\nA. \{choices\[0\]\}\nB. \{choices\[1\]\}\nC. \{choices\[2\]\}\nD. \{choices\[3\]\}\nAnswer:\{answer\}" +train_split_1=validation +train_description_1\="The following are multiple choice questions \(with answers\) about \{subject\}.\n" +few_shot_split_1=dev +train_n_shot_1=5 +run_baselines=False +run_eigenscore=False +md_device=cuda +run_proposed_methods=True +run_layerwise_methods=True +clean_md_device=cuda +is_ood=True
wait